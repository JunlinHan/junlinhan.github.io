<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="Files/jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="./Files/favicon.ico">
<title>Junlin Han</title>
</head>
<body>

<a id="home" class="anchor"></a>
<div id="container">
<div class="container">
<table class="imgtable"><tr><td>
<a><img src="./Files/face.JPG" alt="" align="left" height="250px" width="240"/></a></td>
<td align="left"><p><font size="4"> <b> Junlin Han </b> </font><font size="4"; font style="font-family:Microsoft YaHei"></font><font size="4"></font><br />
<i> Undergraduate student at ANU</i>
<br>
<i> Research student, Data61-CSIRO & ANU</i>
<br>
<i> Visiting research intern at AIML, University of Adelaide</i>
<br /><br />
<a href="https://www.anu.edu.au/"> Australian National Univeristy (ANU)</a></br>
<a href="https://data61.csiro.au/">Data61</a>, <a href="https://www.csiro.au/"> Commonwealth Scientific and Industrial Research Organisation (CSIRO) </a></br >
<a href="https://www.adelaide.edu.au/aiml/">Australian Institute for Machine Learning (AIML)</a>, <a href="https://www.adelaide.edu.au/">University of Adelaide </a></br>
<br />Location: <del>Synergy Building, CSIRO Black Mountain Site, Acton ACT 2601, Australia  </del>
<br>
AIML Building, Lot Fourteen, Adelaide SA 5000, Australia
<br />
<class="staffshortcut">
 <A HREF="#Profile">Profile</A> |
<A HREF="#News">News</A> |
 <A HREF="#Interest">Research Interests</A> |
 <A HREF="#Education">Education</A> |
  <A HREF="#Education">Experience </A> |
 <A HREF="#Publications">Publications</A> |
 <A HREF="#Services">Services</A> |
 <A HREF="#Skills">Skills</A> |
 <A HREF="#Awards">Awards</A>|
  <A HREF="#Miscs">Miscs</A>
<br />
Email: junlin.han@data61.csiro.au (preferred), junlinhcv@gmail.com, junlin.han@adelaide.edu.au <br />
[<a href="https://github.com/junlinhan" target="_blank">GitHub</a>]
[<a href="./Files/CV.pdf">Curriculum Vitae</a>]
[<a href="https://scholar.google.com/citations?user=5L0Uj_IAAAAJ&hl=en&authuser=1&oi=ao" target="_blank">Google Scholar</a>]
[<a href="https://twitter.com/han_junlin" target="_blank">Twitter</a>]
</td></tr></table>





<A NAME="Profile"><h2>Profile</h2></A>
<b>Greetings, welcome to my website!</b>
<ul>
<li>I'm a 4th year undergraduate student at ANU. I work at Data61 (formerly known as NICTA) and ANU with <a href="https://people.csiro.au/P/L/Lars-Petersson">Dr. Lars Petersson</a> and <a href="http://users.cecs.anu.edu.au/~hongdong/">Prof. Hongdong Li</a>, and I'm currently visiting AIML, University of Adelaide, advised/hosted by <a href="https://cs.adelaide.edu.au/~ianr/">Prof. Ian Reid</a>.</li>
</ul>

<A NAME="News"><h2>News</h2
  ></A>
<ul>
<li>[10.2022] Selected as a top reviewer in <a href="https://nips.cc/Conferences/2022/ProgramCommittee"> NeurIPS 2022</a>!    </li>
<li>[08.2022] The journal version of Contrastive Underwater Restoration (CWR) accepted to <a href="https://www.mdpi.com/journal/remotesensing"> Remote Sensing</a>.    </li>
<li>[07.2022] Blind Image Decomposition (BID) accepted to <a href="https://eccv2022.ecva.net/"> ECCV 2022</a>! A new low-level vision task that better adapts to complex real-world scenarios, check our <a href = "https://junlinhan.github.io/projects/BID.html"> project page</a> for more.  </li>
<li>[05.2022] You Only Cut Once (YOCO) accepted to <a href="https://icml.cc/"> ICML 2022</a>! Check <a href="https://arxiv.org/abs/2201.12078"> here </a> for our work on how to perform data augmentation. </li>
<li>[12.2021] I joined <a href="https://www.adelaide.edu.au/aiml/">Australian Institute for Machine Learning (AIML)</a>, <a href="https://www.adelaide.edu.au/">University of Adelaide </a> as a visiting research intern, hosted by <a href="https://cs.adelaide.edu.au/~ianr/">Prof. Ian Reid</a>! </li>
<li>[04.2021] DCLGAN (Dual Contrastive Learning) accepted to <a href="https://data.vision.ee.ethz.ch/cvl/ntire21/">NTIRE</a> (<a href="http://cvpr2021.thecvf.com/">CVPRW</a>) 2021 as <font color="red">oral </font> presentation. The new SOTA method for unsupervised image-to-image translation.  </li>
<li>[03.2021] Contrastive Underwater Restoration (CWR) accepted to <a href="https://igarss2021.com/">IGARSS</a> 2021 as <font color="red">oral </font> presentation. HICRD dataset is also released. </li>
</ul>

<A NAME="Interest"><h2>Research Interests</h2></A>
<ul>
<li>My research interests lie in computer vision, deep learning, and artificial intelligence.  </li>
<li>Specifically, I study visual machines from two perspectives:
  <br>
  First, I am interested in building intelligent machines that may perceive, learn, and think more like humans, where such machines should be more robust and applicable in real-world environments.  
  <br>
  The second perspective is to unveil the perception and cognitive properties of machines, where I enjoy diving into questions like: How do machines see the world? What visual data do machines memorize?  
  <br>
  These two programs are inseparable, for instance, having a deeper understanding of machines should advance the development of more powerful AI systems.   </li>

<!-- <li>My work span content creation, visual perception, visual recognition, scene understanding, image restoration/enhancement, representation learning, self-supervised learning, data augmentation, curved geometry, anomaly detection, memorability, etc.</li>  -->
</ul>




<A NAME="Education"><h2>Education</h2></A>
<b>Undergraduate (02.2019 - 06.2023)</b>
<ul>
<li>B.S. Information Technology (Honours), <a href="https://cecs.anu.edu.au/">College of Engineering and Computer Science</a>, <a href="https://www.anu.edu.au/">ANU</a>
</li>
&nbsp; GPA in US standard: 3.95/4.0
<!-- <li>Some courseworks: Computer Vision (7.0/7.0), Discrete Mathematical Models (7.0/7.0), Programming as Problem Solving (7.0/7.0), Statistical Techniques (7.0/7.0), Programming for Scientists (7.0/7.0), Relational Databases(7.0/7.0), Information Theory (6.0/7.0).</li> -->
<!-- <li>Public online courses: CS231N: Convolutional Neural Networks for Visual Recognition, CS131: Computer Vision: Foundations and Applications, CS231A: Computer Vision, From 3D Reconstruction to Recognition, and CS224n: Natural Language Processing with Deep Learning. </li> -->
</ul>

<A NAME="Experience"><h2>Experience</h2></A>
<b>Visiting Research Intern at AIML, University of Adelaide (12.2021 - ongoing)</b>
<ul>
<li> Topics: data-efficient learning, visual recognition, memorability </li>
<li> Advised/Hosted by <a href="https://cs.adelaide.edu.au/~ianr/">Prof. Ian Reid</a>
</ul>

<b>Research Student at Data61-CSIRO & ANU (08.2020 - ongoing)</b>
<ul>
<li> Topics: low-level vision, generative models, self-supervised learning </li>
<li> Advised by <a href="https://people.csiro.au/P/L/Lars-Petersson">Dr. Lars Petersson</a>, <a href="http://users.cecs.anu.edu.au/~hongdong/">Prof. Hongdong Li</a>
</ul>

<!-- define a function to add publication -->
<script type="text/javascript">
  function show_hide(eid) {
    var x = document.getElementById(eid);
    if (x.style.display === "none") {
      x.style.display = "block";
    } else {
      x.style.display = "none";
    }
  }

  function add_publication(title, img, author, note, link, bib, tag){
    // link=[[url, arXiv],]
    document.write('<tr>')
    if (link!=null) {
      document.write(`<td><div style="width: 230px">\
      <a target="_blank" href=${link[0][0]}>\
      <img width="230" height="130" src=${img}></a>\
      </div></td>`)
    } else {
      document.write(`<td><div style="width: 230px">\
      <img width="230" height="130" src=${img}></a>\
      </div></td>`)
    }

    document.write('<td>')
    document.write(`<p class="title">${title}</p>`)
    document.write(`<p class="author">${author}</p>`)
    if (note) {document.write(`<p class="note">${note}</p>`)}
    if (link!=null) {
      document.write('<p class="link">')
      for (var idx = 0; idx < link.length; idx++){
        document.write(`<a target="_blank" href=${link[idx][0]}>[${link[idx][1]}]</a>&nbsp;`)}
      document.write('</p>')
    }
    document.write('</td></tr>')

  }
</script>

<A NAME="Publications"><h2>Publications</h2></A>


<table>
  <script type="text/javascript">
      add_publication(title='What Images are More Memorable to Machines?',
                   img='./paperimages/paper9.png',
                   author='<b>Junlin Han</b>, Huangying Zhan, Jie Hong, Pengfei Fang, <br> Hongdong Li, Lars Petersson, Ian Reid',
                   note='Preprint',
                   link=[["https://junlinhan.github.io/projects/machinemem.html","Project page"],["https://arxiv.org/abs/2211.07625","arXiv"], ["https://arxiv.org/pdf/2211.07625.pdf","pdf"], ["https://github.com/JunlinHan/MachineMem","Code"],["./bibtex/paper9.txt","BibTex"]]);
  add_publication(title='CropMix: Sampling a Rich Input Distribution via Multi-Scale Cropping',
                   img='./paperimages/paper8.png',
                   author='<b>Junlin Han</b>, Lars Petersson, Hongdong Li, Ian Reid',
                   note='Preprint',
                   link=[["https://arxiv.org/abs/2205.15955","arXiv"], ["https://arxiv.org/pdf/2205.15955.pdf","pdf"], ["https://github.com/JunlinHan/cropmix","Code"],["./bibtex/paper8.txt","BibTex"]]);
  add_publication(title='You Only Cut Once: Boosting Data Augmentation with a Single Cut',
                   img='./paperimages/paper7.jpg',
                   author='<b>Junlin Han</b>, Pengfei Fang, Weihao Li, Jie Hong, Ali Armin, <br> Ian Reid, Lars Petersson, Hongdong Li',
                   note='ICML, 2022',
                   link=[["https://arxiv.org/abs/2201.12078","arXiv"], ["https://arxiv.org/pdf/2201.12078.pdf","pdf"], ["https://proceedings.mlr.press/v162/han22a.html","PMLR"], ["https://github.com/JunlinHan/YOCO","Code"], ["./Files/YOCO_slide.pptx","Slide"], ["./bibtex/paper7.txt","BibTex"]]);
  add_publication(title='Blind Image Decomposition',
                 img='./projects/resources/paper5/BID.gif',
                 author='<b>Junlin Han</b>, Weihao Li, Pengfei Fang, Chunyi Sun, Jie Hong, Ali Armin, <br>Lars Petersson, Hongdong Li',
                 note='ECCV, 2022',
                 link=[["https://junlinhan.github.io/projects/BID.html","Project page"], ["https://arxiv.org/abs/2108.11364","arXiv"], ["https://arxiv.org/pdf/2108.11364.pdf","pdf"], ["https://github.com/JunlinHan/BID","Code"], ["https://github.com/JunlinHan/BID","Dataset"], ["https://youtu.be/wkyJDjUPCkg","Video"], ["./Files/BID_slide.pptx","Slide"], ["./Files/BID_poster.pdf","Poster"], ["./bibtex/paper5.txt","BibTex"]]);
  add_publication(title='Underwater Image Restoration via Contrastive Learning and a Real-world Dataset',
                 img='./paperimages/paper4.JPG',
                 author='<b>Junlin Han</b>, Mehrdad Shoeiby, Tim Malthus, Elizabeth Botha, Janet Anstee, <br> Saeed Anwar, Ran Wei, Ali Armin, Hongdong Li, Lars Petersson',
                 note='Remote Sensing, 2022',
                 link=[["https://www.mdpi.com/2072-4292/14/17/4297","Paper"], ["https://github.com/JunlinHan/CWR","Code"],["https://github.com/JunlinHan/CWR","Dataset"],["./bibtex/paper4.txt","BibTex"]]);
    add_publication(title='Single Underwater Image Restoration by Contrastive Learning',
                    img='./paperimages/paper2.JPG',
                    author='<b>Junlin Han</b>, Mehrdad Shoeiby, Tim Malthus, Elizabeth Botha, Janet Anstee, Saeed Anwar, Ran Wei, Lars Petersson, Ali Armin',
                    note='IGARSS (<font color="red">oral</font>), 2021',
                    link=[["https://arxiv.org/abs/2103.09697","arXiv"], ["https://arxiv.org/pdf/2103.09697.pdf","pdf"],
                    ["https://github.com/JunlinHan/CWR","Code"],["https://github.com/JunlinHan/CWR","Dataset"]
                    ,["./bibtex/paper2.txt","BibTex"]]);
   add_publication(title='Dual Contrastive Learning for Unsupervised Image-to-Image Translation',
                    img='./paperimages/paper1.PNG',
                    author='<b>Junlin Han</b>, Mehrdad Shoeiby, Lars Petersson, Ali Armin',
                      note=' NTIRE, CVPRW (<font color="red">oral</font>), 2021',
                    link=[["https://arxiv.org/abs/2104.07689","arXiv"], ["https://arxiv.org/pdf/2104.07689.pdf","pdf"], ["https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Han_Dual_Contrastive_Learning_for_Unsupervised_Image-to-Image_Translation_CVPRW_2021_paper.pdf","CVF"],
                    ["https://github.com/JunlinHan/DCLGAN","Code"],["https://youtu.be/w0oltXvLgmI","Video"],["./Files/DCLGAN_slide.pptx","Slide"],["./bibtex/paper1.txt","BibTex"]]);
      add_publication(title='NeRFEditor: Differentiable Style Decomposition for Full 3D Scene Editing',
                    img='./paperimages/paper10.png',
                    author='Chunyi Sun, Yanbing Liu, <b>Junlin Han</b>, Stephen Gould',
                    note='Coming soon',);                  
      add_publication(title='GOSS: Towards Generalized Open-set Semantic Segmentation',
               img='./paperimages/paper3.png',
               author='Jie Hong, Weihao Li, <b>Junlin Han</b>, Jiyang Zheng, Pengfei Fang, <br> Mehrtash Harandi, Lars Petersson',
               note='Preprint',
                   link=[["https://arxiv.org/abs/2203.12116","arXiv"], ["https://arxiv.org/pdf/2203.12116.pdf","pdf"],["https://github.com/JHome1/GOSS_Segmentor","Code"], ["./bibtex/paper3.txt","BibTex"]]);
   add_publication(title='Curvature-Aware Geometry for Visual Anomaly Recognition',
                img='./paperimages/paper6.JPG',
                author='Jie Hong, Pengfei Fang, Weihao Li, <b>Junlin Han</b>, Lars Petersson, Mehrtash Harandi',
                note='Preprint',
                link=[["https://arxiv.org/abs/2208.01188","arXiv"], ["https://arxiv.org/pdf/2208.01188.pdf","pdf"],["./bibtex/paper6.txt","BibTex"]]);


  </script>
  </table>


<p><br /></p>

<!-- <A NAME="Talks"><h2>Talks</h2></A>
<b>I share some of my talks and slides here, please feel free to use them if you are interested in.</b>
<ul>
<li><b> Image synthesis</b> </li>
<a href="./Files/StyleGAN.pptx">StyleGAN</a>
<li><b> Image-to-Image Translation</b> </li>
<a href="./Files/DCLGAN_slide.pptx">DCLGAN</a>
</ul> -->


<A NAME="Services"><h2>Services</h2></A>
<ul>
<li><b>Conference review</b></li>
CVPR 2022 2023, ICML 2022, ECCV 2022, Neurips 2022, ACCV 2022, AAAI 2023, ICLR 2023
<br>
<li><b>Journal review</b> </li>
Transactions on Image Processing (TIP), Pattern Recognition, Neurocomputing,  Journal of Oceanic Engineering (JOE)
<br>
<li><b>Workshop review</b> </li>
NTIRE (CVPRW) 2021
</ul>
</font>

<A NAME="Skills"><h2>Skills</h2></A>
<ul>
<li><b>Programming Language</b></li>
Proficient in MATLAB, Python
<br>
Familiar with Java, Haskell, R, CSS, Html, Assembly (ARMV7), SQL
<Li><b>Tool</b></li>
NumPy, PyTorch, Git, LaTeX
<li><b>Language</b></li>
English (Fluent), Madarian (Native)
</ul>
</font>

<A NAME="Awards"><h2>Awards</h2></A>
<ul>
  <li><b>Top Reviewer, 2022</b></br>
    NeurIPS (Conference on Neural Information Processing Systems)
    </li>
  <li><b>Second Best Presentation Award, 2021</b></br>
  AIM (Active Integrated Matter) Conference
  </li>
<li><b>Top-up Scholarship, 2021</b></br>
for research work at Data61-CSIRO
</li>
<li><b>Undergraduate Vacation Scholarship, 2020</b></br>
for summer research at Data61-CSIRO
</li>
</ul>
</font>

<A NAME="Miscs"><h2>Miscs</h2></A>
<ul>
<li>At the beginning, I was born and raised in <a href="https://en.wikipedia.org/wiki/Chengdu">Chengdu</a>, which is famous for spice and pandas. </li>
</ul>
</font>

</br>
</br>


<a href="https://www.easycounter.com/">
<img src="https://www.easycounter.com/counter.php?junlin"
border="0" alt="Web Counter"></a>
<br><a href="https://www.easycounter.com/">unique visitors since April 2021</a>
</body>
</html>
